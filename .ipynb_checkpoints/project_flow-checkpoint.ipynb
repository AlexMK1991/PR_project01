{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset, preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity vectors shape: (2445, 35)\n",
      "Targets shape: (2445,)\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from pandas_profiling import ProfileReport\n",
    "np.random.seed(2020)\n",
    "\n",
    "dataset_df = get_table('../project01/android.csv').dropna()\n",
    "mask = (dataset_df['battery_plugged'] == 0) | (dataset_df['battery_plugged'] == 1)\n",
    "dataset_df = dataset_df[mask]\n",
    "# month in 8-12, 1-3, day in 1-31\n",
    "# the following replacements keep 'monthday' chronologically sorted when hashed later\n",
    "dataset_df['month'][dataset_df['month'] == 1] = 13\n",
    "dataset_df['month'][dataset_df['month'] == 2] = 14\n",
    "dataset_df['month'][dataset_df['month'] == 3] = 15\n",
    "dataset_df['monthday'] = dataset_df['month']*100 + dataset_df['day']\n",
    "\n",
    "text = 'packages_running_'\n",
    "keep = [i for i in dataset_df.columns if text in i] + ['battery_plugged'] + ['battery_level'] + ['slot'] + ['monthday']\n",
    "dataset_df = dataset_df[keep[:49] + keep[50:54] + keep[55:]]\n",
    "dataset_df = dataset_df.dropna().T.drop_duplicates().T.reset_index()\n",
    "dataset_df['md_key'] = hash_states(dataset_df['monthday'].to_numpy()[:,None])\n",
    "dataset_df = dataset_df.drop(['monthday', 'slot'], axis=1)\n",
    "dataset_df = dataset_df.drop(['packages_running_android', 'packages_running_com.android.calculator2',\\\n",
    "                             'packages_running_com.android.keychain','packages_running_com.android.packageinstaller',\\\n",
    "                             'packages_running_com.android.providers.applications', 'packages_running_com.android.providers.downloads',\\\n",
    "                             'packages_running_com.google.android.email', 'packages_running_edu.udo.cs.ess.mobidac.target',\\\n",
    "                             'packages_running_org.openintents.filemanager', 'packages_running_stream.android'], axis=1)\n",
    "\n",
    "# get indices of dataset elements per day, so that we can use this partitioning of the data in training and validation\n",
    "num_days = dataset_df['md_key'].to_numpy().max() + 1\n",
    "# by day is a list that for each day, contains all dataset indices for that day\n",
    "by_day = [np.array(dataset_df.index[dataset_df['md_key'] == i].tolist()) for i in range(num_days)]\n",
    "# keep only days with at least 5 samples\n",
    "by_day_filtered = [item for item in by_day if len(item) > 4]\n",
    "# we can access day i by calling dataset_df.loc[by_day[i]]\n",
    "\n",
    "\n",
    "# in this state space, battery plugged is the last column: activity_vectors[:,-1]\n",
    "activity_vectors = dataset_df.drop(['index', 'battery_level', 'md_key'], axis=1).to_numpy()\n",
    "targets = dataset_df['battery_level'].to_numpy()\n",
    "print('Activity vectors shape:', activity_vectors.shape)\n",
    "print('Targets shape:', targets.shape)\n",
    "#profile = ProfileReport(dataset_df, title=\"Filtered Profiling Report\")\n",
    "#profile.to_file(\"filtered_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the state space\n",
    "\n",
    "This is an interface for attempting some clustering, or some other informed pruning of the state space. It is however necessary that the outputs of the state space transform are still binary vectors, as this guarantees compatibility with later modules. Also, the final column activity_vectors$[:,-1]$ should remain untouched, as it stores the battery_plugged state which we need for the regressor split later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sign Targets, binary, shape (1, 2445)\n",
      "activity vectors shape (35, 2445)\n",
      "Activity vectors shape (36, 2445)\n",
      "Activity vectors[0] shape (2445,)\n",
      "Activity vectors, where finite, shape (36, 2445)\n",
      "Activity vectors,where not nan, shape (36, 2445)\n",
      "Gain shape (35,)\n",
      "Gini shape (35,)\n"
     ]
    }
   ],
   "source": [
    "def get_non_nan(examples):\n",
    "    \"\"\"\n",
    "    Returns the position of the input, where the measurements weren't nan.\n",
    "    \n",
    "    Assumes the examples to be a np array.\n",
    "    \"\"\"\n",
    "    return ~np.isnan(examples)\n",
    "    \n",
    "    \n",
    "def _entropy(points, n):\n",
    "    \"\"\"\n",
    "    Entropy for n classes, enumerated, i.e. labels of classes = np.arange(n)\n",
    "    \n",
    "    It may be needed to change the clip to something smaler.\n",
    "    Points is assumed to be a vector (for example the Targets).\n",
    "    \"\"\"\n",
    "    p = np.asarray([np.sum([points==i])/np.prod(points.shape) for i in np.arange(n)])\n",
    "    q = np.clip(p[p>0], 1e-15, 1)\n",
    "    return -np.sum( q * np.log2(q))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Information gain ratio is the ratio between information gain and\n",
    "the entropy of the feature's value distribution. \n",
    "The score was introduced in [Quinlan1986]_\n",
    "to alleviate overestimation for multi-valued features. \n",
    "See `Wikipedia entry on gain ratio\n",
    "<http://en.wikipedia.org/wiki/Information_gain_ratio>`_.\n",
    ".. [Quinlan1986] J R Quinlan: Induction of Decision Trees, Machine Learning, 1986.\n",
    "\"\"\"\n",
    "\n",
    "def GainRatio(examples,n):\n",
    "    \"\"\"\n",
    "    Returns the Information Gain-Ration, that is \\frac{Information Gain}{Intrinsic Value}\n",
    "\n",
    "    examples are all training examples, given as 2-d numpy array.\n",
    "    Assuming H is the Entropy and EX are the examples[0], than H(EX)shall be the same as h_class.\n",
    "    nan_adjustment is neccesary in a preprocessing step.\n",
    "    The Information Gain is h_class-h_residual.\n",
    "    h_attribute is the Intrinsic Value.\n",
    "    If h_attribute = 0, than the Information Gain-Ration is the same as the Information Gain.\n",
    "    \"\"\"\n",
    "    h_class = _entropy(examples[0],n)\n",
    "    \n",
    "    #p_val = probability to get val if drawn uniformly \n",
    "    p_val=np.asarray([np.unique(examples[j+1],return_counts=True)[1]/examples.shape[1] for j in np.arange(examples.shape[0]-1)])\n",
    "    p_val[p_val==0]=1\n",
    "    h_residual = np.asarray([p_val[j]@[_entropy(examples[0][examples[j+1] == val],n)for val in np.unique(examples[j+1])]for j in np.arange(examples.shape[0]-1)])\n",
    "    h_attribute = np.asarray([- p_val[j] @ np.log2(p_val[j])for j in np.arange(examples.shape[0]-1)])\n",
    "    return (h_class - h_residual) / h_attribute\n",
    "\n",
    "def _gini(targets):\n",
    "    \"\"\"Gini index of class-distribution matrix\"\"\"\n",
    "    p = np.sum(targets==1)/np.prod(targets.shape)\n",
    "    return 1-(p**2+(1-p)**2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Gini index is the probability of incorrectly labeling a randomly chosen element if the element was chosen\n",
    "randomly according to the class distributions. The Gini gain maximises the expected reduction in the Gini index.\n",
    "For reference see `Computational Statistics & Data Analysis on Gini Gain\n",
    "<https://www.sciencedirect.com/science/article/abs/pii/S0167947306005093>`_.\n",
    "\"\"\"\n",
    "\n",
    "def GiniGain(examples):\n",
    "    \"\"\"\n",
    "    Returns the Gini split of the examples, choose the smalest one to get maximum Gini gain.\n",
    "    \n",
    "    Targets have to be binary!\n",
    "    examples are all training examples, given as 2-d numpy array.\n",
    "    The orientation of the numpy array is assumed ro be the same as for GainRatio.\n",
    "    nan_adjustment is neccesary in a preprocessing step.\n",
    "    \"\"\"\n",
    "    p_val = np.asarray([np.unique(examples[j+1],return_counts=True)[1]/examples.shape[1] for j in np.arange(examples.shape[0]-1)])\n",
    "    gini_split = np.asarray([p_val[j]@np.asarray([_gini(examples[0][examples[j+1]==val])for val in np.unique(examples[j+1])])for j in np.arange(examples.shape[0]-1)])\n",
    "    return gini_split\n",
    "\n",
    "\n",
    "print('Sign Targets, binary, shape', np.asarray([np.sign(targets)==1]).shape)\n",
    "print('activity vectors shape',activity_vectors.T.shape)\n",
    "\n",
    "targets_binary_1 = np.asarray([np.sign(targets)==1]).astype(int)\n",
    "\n",
    "activity_vectors_new = np.concatenate((targets_binary_1, activity_vectors.T), axis=0)\n",
    "print('Activity vectors shape', activity_vectors_new.shape)\n",
    "print('Activity vectors[0] shape', activity_vectors_new[0].shape)\n",
    "print('Activity vectors, where finite, shape', get_finite(activity_vectors_new).shape)\n",
    "print('Activity vectors,where not nan, shape', get_non_nan(activity_vectors_new).shape)\n",
    "print('Gain shape', GainRatio(activity_vectors_new,2).shape)\n",
    "print('Gini shape', GiniGain(activity_vectors_new).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape, Id: (2445, 35)\n",
      "States shape, Gini: (2445, 35)\n",
      "States shape, Gain: (2445, 35)\n",
      "\n",
      "Gain and Gini can be pruned at will. The criterion is given now.\n"
     ]
    }
   ],
   "source": [
    "def state_space_transform(targets, activity_vectors, number_classes, mode='Id'):\n",
    "    \"\"\"\n",
    "    Transforms/prunes the state space of the input.\n",
    "    \n",
    "    Possible states are 'Id', 'Clown', 'Gain','Gini'.\n",
    "    !Gain is not consistent with Gini! should be changed, but am to tired now...\n",
    "    Gain sorts by Information Gain Ratio. As of now, starting with the worst.\n",
    "    Gini sorts by Gini Gain. Starting with the best feature, ending with the worst.\n",
    "    \"\"\"\n",
    "    if mode == 'Id':\n",
    "        out = activity_vectors[:,:-1]\n",
    "    elif mode == 'Clown':\n",
    "        out = np.ones_like(activity_vectors[:,:-1])\n",
    "    elif mode == 'Gain':\n",
    "        n= number_classes\n",
    "        activity_vectors_new = np.concatenate((targets, activity_vectors.T), axis=0)\n",
    "        gain_ratio = GainRatio(activity_vectors_new,n)\n",
    "        gain_ratio = np.reshape(gain_ratio, (gain_ratio.shape[0],1))\n",
    "        activity_vectors_new = activity_vectors_new[1:,:]\n",
    "        pre_out = np.concatenate((gain_ratio.T,activity_vectors_new.T), axis=0)\n",
    "        pre_out = pre_out[:-1,:]\n",
    "        sorted_pre_out = pre_out.T[pre_out.T[:,0].argsort()]\n",
    "        sorted_pre_out = sorted_pre_out.T\n",
    "        out = sorted_pre_out[:,1:]\n",
    "    elif mode == 'Gini':\n",
    "        activity_vectors_new = np.concatenate((targets, activity_vectors.T), axis=0)\n",
    "        gini_gain = GiniGain(activity_vectors_new)\n",
    "        gini_gain = np.reshape(gini_gain, (gini_gain.shape[0],1))\n",
    "        activity_vectors_new = activity_vectors_new[1:,:]\n",
    "        pre_out = np.concatenate((gini_gain.T,activity_vectors_new.T), axis=0)\n",
    "        pre_out = pre_out[:-1,:]\n",
    "        sorted_pre_out = pre_out.T[pre_out.T[:,0].argsort()]\n",
    "        sorted_pre_out = sorted_pre_out.T\n",
    "        out = sorted_pre_out[:,1:]\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown state space transform!\")\n",
    "    return np.concatenate([out, activity_vectors[:,-1, None]], axis=1)\n",
    "        \n",
    "number_classes = 2\n",
    "states = state_space_transform(targets_binary_1, activity_vectors, number_classes, mode='Id')\n",
    "print('States shape, Id:', states.shape)        \n",
    "states = state_space_transform(targets_binary_1, activity_vectors, number_classes, mode='Gini')\n",
    "print('States shape, Gini:', states.shape)\n",
    "states = state_space_transform(targets_binary_1, activity_vectors, number_classes, mode='Gain')\n",
    "print('States shape, Gain:', states.shape)\n",
    "\n",
    "print('\\nGain and Gini can be pruned at will. The criterion is given now.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign labels to the states\n",
    "\n",
    "This assigns an integer label to each unique state, allowing us to connect different data structures in a way that we always know which states they are representing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique states: 637\n",
      "by_day_filtered example: [448 449 450 451 452 453 454]\n",
      "hash_by_day example:     [ 26 158 158 158 158 156 156]\n"
     ]
    }
   ],
   "source": [
    "out_labels = hash_states(states)\n",
    "dataset_df['out_labels'] = out_labels\n",
    "helper_states = lookup_states(np.arange(0, out_labels.max()+1), dataset_df['out_labels'].values, states)\n",
    "num_unique_states = out_labels.max()+1\n",
    "print('Number of unique states:', num_unique_states)\n",
    "\n",
    "hash_by_day = [dataset_df['out_labels'].loc[inds].values for inds in by_day_filtered]\n",
    "print('by_day_filtered example:', by_day_filtered[18])\n",
    "print('hash_by_day example:    ', hash_by_day[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training, validation and test sets for the prediction component\n",
    "\n",
    "This is just a dummy implementation, the validation scheme on the task description can be implemented when we are aware of all interactions between all modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences in training set: 94\n",
      "Number of sequences in validation set: 11\n",
      "Transition matrix shape: (637, 637)\n"
     ]
    }
   ],
   "source": [
    "ind_set = np.arange(len(hash_by_day))\n",
    "ind_set = np.random.permutation(ind_set).astype(int)\n",
    "\n",
    "split = 0.90\n",
    "ind_set_train = ind_set[:int(split*len(ind_set))]\n",
    "ind_set_valid = ind_set[int(split*len(ind_set)):]\n",
    "\n",
    "print('Number of sequences in training set:', len(ind_set_train))\n",
    "print('Number of sequences in validation set:', len(ind_set_valid))\n",
    "\n",
    "train_set_prediction = [hash_by_day[ind] for ind in ind_set_train]\n",
    "valid_set_prediction = [hash_by_day[ind] for ind in ind_set_valid]\n",
    "\n",
    "P = fit_predictor(train_set_prediction, num_unique_states, mode='MAP')\n",
    "print('Transition matrix shape:', P.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction output transform\n",
    "\n",
    "Apply the transition models to generate distributions over future states. These distributions need to be sent back to the state space, because we need to plug them into a regressor trained in the state space later. There are several concievable ways to go from a distribution over states to an element of the state space, and this cell provides an interface for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document these!\n",
    "def predict(list_of_seqs, P, N_steps, num_unique_states):\n",
    "    in_flat = np.concatenate([item[:-N_steps] for item in list_of_seqs])\n",
    "    one_hot_prediction_input = one_hot_encode(in_flat, num_states = num_unique_states)\n",
    "    pred = np.power(P, N_steps)\n",
    "    # calculate a distribution over future states\n",
    "    return pred @ one_hot_prediction_input\n",
    "\n",
    "def list_to_prediction_targets(list_of_seqs, N_steps, labels, state_set):\n",
    "    targets = np.concatenate([item[N_steps:] for item in list_of_seqs])\n",
    "    return lookup_states(targets, labels, state_set)\n",
    "\n",
    "def prediction_output_transform(pred_out, labels, state_set, mode):\n",
    "    if mode == 'activity_dist':\n",
    "        return state_dist_to_activity_dist(pred_out, labels, state_set)\n",
    "    elif mode == 'argmax':\n",
    "        return state_dist_to_most_likely_state(pred_out, labels, state_set)\n",
    "    elif mode == 'nearest_neighbor':\n",
    "        distribution = state_dist_to_activity_dist(pred_out, labels, state_set)\n",
    "        return distribution >= 0.5\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown prediction output transform!\")\n",
    "        \n",
    "def bit_flips(prediction_dist, target):\n",
    "    dist_rounded = prediction_dist >= 0.5\n",
    "    loss = dist_rounded.astype(int) == target.astype(int)\n",
    "    return 1 - loss.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction loss over the data for 1 time step(s): mean: 0.4523963185924837 std: 0.09233427479952037\n",
      "Prediction bit flips over the data for 1 time step(s): mean: 0.21349206349206348 std: 0.07196635546289737\n"
     ]
    }
   ],
   "source": [
    "N_steps = 1\n",
    "estimate = predict(valid_set_prediction, P, N_steps, num_unique_states)\n",
    "# convert to sets of individual distributions over activity components\n",
    "prediction = prediction_output_transform(estimate, dataset_df['out_labels'].values, states, 'activity_dist')\n",
    "# simple targets - just time-shifted the input by N_steps\n",
    "pred_targets = list_to_prediction_targets(valid_set_prediction, N_steps, dataset_df['out_labels'].values, states)\n",
    "# calculate loss\n",
    "loss = BCE(prediction, pred_targets) #percentage bitflips as alternatives\n",
    "loss_bit = bit_flips(prediction, pred_targets) #percentage bitflips as alternatives\n",
    "# print reduced loss\n",
    "print('Prediction loss over the data for', N_steps, 'time step(s): mean:', loss.mean(), 'std:', loss.std())\n",
    "print('Prediction bit flips over the data for', N_steps, 'time step(s): mean:', loss_bit.mean(), 'std:', loss_bit.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the target space\n",
    "\n",
    "Sebastian already offered some advice here, like taking the square root of the values to allow for a better line fit through them. This cell provides an interface for such techniques. Note that these should always be invertible, because we need to convert the regressor output back to the original target space. This should be implemented in the 'Backward' direction case.\n",
    "\n",
    "This part is a little hacky, and might need some changes to be able to elegantly account for using two regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_space_transform(targets, mode='Id', direction='Forward'):\n",
    "    if mode == 'Id':\n",
    "        if direction == 'Forward':\n",
    "            return targets\n",
    "        elif direction == 'Backward':\n",
    "            return targets\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unknown direction!\")\n",
    "    elif mode == 'Sqrt':\n",
    "        if direction == 'Forward':\n",
    "            return np.sqrt(np.abs(targets))\n",
    "        elif direction == 'Backward':\n",
    "            return -np.power(targets, 2)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unknown direction!\")   \n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown target space transform!\")\n",
    "        \n",
    "targets_transformed = target_space_transform(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training, validation and test sets for the regression component\n",
    "\n",
    "Do this for negative and positive targets separately!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression component train/valid/test here!\n",
      "Number of sequences in training set: 2200\n",
      "Number of sequences in validation set: 245\n"
     ]
    }
   ],
   "source": [
    "print('Regression component train/valid/test here!')\n",
    "ind_set_regressor = np.arange(targets_transformed.shape[0])\n",
    "ind_set_regressor = np.random.permutation(ind_set_regressor).astype(int)\n",
    "\n",
    "split = 0.9\n",
    "ind_set_regressor_train = ind_set_regressor[:int(split*len(ind_set_regressor))]\n",
    "ind_set_regressor_valid = ind_set_regressor[int(split*len(ind_set_regressor)):]\n",
    "\n",
    "print('Number of sequences in training set:', len(ind_set_regressor_train))\n",
    "print('Number of sequences in validation set:', len(ind_set_regressor_valid))\n",
    "\n",
    "train_states = states[ind_set_regressor_train]\n",
    "train_targets = targets_transformed[ind_set_regressor_train]\n",
    "\n",
    "valid_states = states[ind_set_regressor_valid]\n",
    "valid_targets = targets_transformed[ind_set_regressor_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe check what is X, and what is X.T here...\n",
    "def build_state_mat(states):\n",
    "    return np.concatenate([np.ones((states.shape[0],1)), states], axis=-1).T\n",
    "\n",
    "def fit_regressor(states, targets, mode='MLE', eps=1e-25):\n",
    "    X = build_state_mat(states)\n",
    "    if mode == 'MLE':\n",
    "        return np.linalg.inv(X @ X.T + eps*np.eye(X.shape[0])) @ X @ targets\n",
    "    elif mode == 'MAP':\n",
    "        var = targets.var()\n",
    "        return np.linalg.inv(X @ X.T + var*np.eye(X.shape[0])) @ X @ targets\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown regressor mode!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the charging training set: 88\n",
      "Number of samples in the discharging training set: 2112\n",
      "Number of samples in the charging valid set: 14\n",
      "Number of samples in the discharging valid set: 231\n",
      "Regressor L1 over the charging data: mean: 6.824713463756572 std: 4.93255997852312\n",
      "Regressor L1 over the discharging data: mean: 1.1261263390029126 std: 3.267995721260056\n",
      "Regressor L1 over the data: mean: 1.4517598889888363 std: 3.6344779665913904\n"
     ]
    }
   ],
   "source": [
    "split_regressor = True\n",
    "regressor_mode = 'MAP'\n",
    "if split_regressor:\n",
    "    charging_transform_mode = 'Id'\n",
    "    discharging_transform_mode = 'Sqrt'\n",
    "    train_charging_mask = train_states[:,-1] > 0.5\n",
    "    train_discharging_mask = np.invert(train_charging_mask)\n",
    "    train_states_charging = train_states[train_charging_mask][:,:-1]\n",
    "    train_targets_charging = train_targets[train_charging_mask]\n",
    "    train_states_discharging = train_states[train_discharging_mask][:,:-1]\n",
    "    train_targets_discharging = train_targets[train_discharging_mask]\n",
    "    train_targets_charging_transformed = target_space_transform(train_targets_charging, mode=charging_transform_mode)\n",
    "    train_targets_discharging_transformed = target_space_transform(train_targets_discharging, mode=discharging_transform_mode)\n",
    "    \n",
    "    print('Number of samples in the charging training set:', train_targets_charging.shape[0])\n",
    "    print('Number of samples in the discharging training set:', train_targets_discharging.shape[0])\n",
    "    \n",
    "    w_charging = fit_regressor(train_states_charging, train_targets_charging_transformed, mode=regressor_mode)\n",
    "    w_discharging = fit_regressor(train_states_discharging, train_targets_discharging_transformed, mode=regressor_mode)\n",
    "    \n",
    "    valid_charging_mask = valid_states[:,-1] > 0.5\n",
    "    valid_discharging_mask = np.invert(valid_charging_mask)\n",
    "    valid_states_charging = valid_states[valid_charging_mask][:,:-1]\n",
    "    valid_states_discharging = valid_states[valid_discharging_mask][:,:-1]\n",
    "    valid_targets_charging = valid_targets[valid_charging_mask]\n",
    "    valid_targets_discharging = valid_targets[valid_discharging_mask]\n",
    "    valid_state_mat_charging = build_state_mat(valid_states_charging)\n",
    "    valid_state_mat_discharging = build_state_mat(valid_states_discharging)\n",
    "    valid_charging_out_transformed = valid_state_mat_charging.T @ w_charging\n",
    "    valid_discharging_out_transformed = valid_state_mat_discharging.T @ w_discharging\n",
    "    valid_charging_out = target_space_transform(valid_charging_out_transformed, mode=charging_transform_mode, direction='Backward')\n",
    "    valid_discharging_out = target_space_transform(valid_discharging_out_transformed, mode=discharging_transform_mode, direction='Backward')\n",
    "    loss_regressor_charging = np.abs(valid_charging_out - valid_targets_charging)\n",
    "    loss_regressor_discharging = np.abs(valid_discharging_out - valid_targets_discharging)\n",
    "    \n",
    "    print('Number of samples in the charging valid set:', valid_targets_charging.shape[0])\n",
    "    print('Number of samples in the discharging valid set:', valid_targets_discharging.shape[0])\n",
    "    \n",
    "    print('Regressor L1 over the charging data: mean:', loss_regressor_charging.mean(), 'std:', loss_regressor_charging.std())\n",
    "    print('Regressor L1 over the discharging data: mean:', loss_regressor_discharging.mean(), 'std:', loss_regressor_discharging.std())\n",
    "    \n",
    "    loss_regressor = np.concatenate([loss_regressor_charging, loss_regressor_discharging])\n",
    "    \n",
    "else:\n",
    "    transform_mode = 'Id'\n",
    "    train_targets_transformed = target_space_transform(train_targets, mode=transform_mode)\n",
    "    w = fit_regressor(train_states, train_targets_transformed, mode=regressor_mode)\n",
    "    \n",
    "    valid_state_mat = build_state_mat(valid_states)\n",
    "    valid_out_transformed = valid_state_mat.T @ w\n",
    "    valid_out = target_space_transform(valid_out_transformed, mode=transform_mode, direction='Backward')\n",
    "    loss_regressor = np.abs(valid_out - valid_targets)\n",
    "    \n",
    "print('Regressor L1 over the data: mean:', loss_regressor.mean(), 'std:', loss_regressor.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: MAP regression mode\n",
    "\n",
    "Need to implement this.\n",
    "\n",
    "### Combine Prediction and Regression\n",
    "\n",
    "Core idea: Pick one specific predictor, then do the regression on the same training set. Hopefully the validation scheme for the regressor will provide some justification for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
