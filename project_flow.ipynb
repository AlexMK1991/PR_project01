{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset, preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity vectors shape: (2445, 35)\n",
      "Targets shape: (2445,)\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from pandas_profiling import ProfileReport\n",
    "np.random.seed(2020)\n",
    "\n",
    "dataset_df = get_table().dropna()\n",
    "mask = (dataset_df['battery_plugged'] == 0) | (dataset_df['battery_plugged'] == 1)\n",
    "dataset_df = dataset_df[mask]\n",
    "# month in 8-12, 1-3, day in 1-31\n",
    "# the following replacements keep 'monthday' chronologically sorted when hashed later\n",
    "dataset_df['month'][dataset_df['month'] == 1] = 13\n",
    "dataset_df['month'][dataset_df['month'] == 2] = 14\n",
    "dataset_df['month'][dataset_df['month'] == 3] = 15\n",
    "dataset_df['monthday'] = dataset_df['month']*100 + dataset_df['day']\n",
    "\n",
    "text = 'packages_running_'\n",
    "keep = [i for i in dataset_df.columns if text in i] + ['battery_plugged'] + ['battery_level'] + ['slot'] + ['monthday']\n",
    "dataset_df = dataset_df[keep[:49] + keep[50:54] + keep[55:]]\n",
    "dataset_df = dataset_df.dropna().T.drop_duplicates().T.reset_index()\n",
    "dataset_df['md_key'] = hash_states(dataset_df['monthday'].to_numpy()[:,None])\n",
    "dataset_df = dataset_df.drop(['monthday', 'slot'], axis=1)\n",
    "dataset_df = dataset_df.drop(['packages_running_android', 'packages_running_com.android.calculator2',\\\n",
    "                             'packages_running_com.android.keychain','packages_running_com.android.packageinstaller',\\\n",
    "                             'packages_running_com.android.providers.applications', 'packages_running_com.android.providers.downloads',\\\n",
    "                             'packages_running_com.google.android.email', 'packages_running_edu.udo.cs.ess.mobidac.target',\\\n",
    "                             'packages_running_org.openintents.filemanager', 'packages_running_stream.android'], axis=1)\n",
    "\n",
    "# get indices of dataset elements per day, so that we can use this partitioning of the data in training and validation\n",
    "num_days = dataset_df['md_key'].to_numpy().max() + 1\n",
    "# by day is a list that for each day, contains all dataset indices for that day\n",
    "by_day = [np.array(dataset_df.index[dataset_df['md_key'] == i].tolist()) for i in range(num_days)]\n",
    "# keep only days with at least 5 samples\n",
    "by_day_filtered = [item for item in by_day if len(item) > 4]\n",
    "# we can access day i by calling dataset_df.loc[by_day[i]]\n",
    "\n",
    "\n",
    "# in this state space, battery plugged is the last column: activity_vectors[:,-1]\n",
    "activity_vectors = dataset_df.drop(['index', 'battery_level', 'md_key'], axis=1).to_numpy()\n",
    "targets = dataset_df['battery_level'].to_numpy()\n",
    "print('Activity vectors shape:', activity_vectors.shape)\n",
    "print('Targets shape:', targets.shape)\n",
    "#profile = ProfileReport(dataset_df, title=\"Filtered Profiling Report\")\n",
    "#profile.to_file(\"filtered_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the state space\n",
    "\n",
    "This is an interface for attempting some clustering, or some other informed pruning of the state space. It is however necessary that the outputs of the state space transform are still binary vectors, as this guarantees compatibility with later modules. Also, the final column activity_vectors$[:,-1]$ should remain untouched, as it stores the battery_plugged state which we need for the regressor split later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: (2445, 35)\n"
     ]
    }
   ],
   "source": [
    "def state_space_transform(activity_vectors, mode='Id'):\n",
    "    if mode == 'Id':\n",
    "        out = activity_vectors[:,:-1]\n",
    "    elif mode == 'Clown':\n",
    "        out = np.ones_like(activity_vectors[:,:-1])\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown state space transform!\")\n",
    "    return np.concatenate([out, activity_vectors[:,-1, None]], axis=1)\n",
    "        \n",
    "states = state_space_transform(activity_vectors, mode='Id')\n",
    "print('States shape:', states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign labels to the states\n",
    "\n",
    "This assigns an integer label to each unique state, allowing us to connect different data structures in a way that we always know which states they are representing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique states: 637\n",
      "by_day_filtered example: [448 449 450 451 452 453 454]\n",
      "hash_by_day example:     [ 26 158 158 158 158 156 156]\n"
     ]
    }
   ],
   "source": [
    "out_labels = hash_states(states)\n",
    "dataset_df['out_labels'] = out_labels\n",
    "helper_states = lookup_states(np.arange(0, out_labels.max()+1), dataset_df['out_labels'].values, states)\n",
    "num_unique_states = out_labels.max()+1\n",
    "print('Number of unique states:', num_unique_states)\n",
    "\n",
    "hash_by_day = [dataset_df['out_labels'].loc[inds].values for inds in by_day_filtered]\n",
    "print('by_day_filtered example:', by_day_filtered[18])\n",
    "print('hash_by_day example:    ', hash_by_day[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training, validation and test sets for the prediction component\n",
    "\n",
    "This is just a dummy implementation, the validation scheme on the task description can be implemented when we are aware of all interactions between all modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences in training set: 94\n",
      "Number of sequences in validation set: 11\n",
      "Transition matrix shape: (637, 637)\n"
     ]
    }
   ],
   "source": [
    "ind_set = np.arange(len(hash_by_day))\n",
    "ind_set = np.random.permutation(ind_set).astype(int)\n",
    "\n",
    "split = 0.90\n",
    "ind_set_train = ind_set[:int(split*len(ind_set))]\n",
    "ind_set_valid = ind_set[int(split*len(ind_set)):]\n",
    "\n",
    "print('Number of sequences in training set:', len(ind_set_train))\n",
    "print('Number of sequences in validation set:', len(ind_set_valid))\n",
    "\n",
    "train_set_prediction = [hash_by_day[ind] for ind in ind_set_train]\n",
    "valid_set_prediction = [hash_by_day[ind] for ind in ind_set_valid]\n",
    "\n",
    "P = fit_predictor(train_set_prediction, num_unique_states, mode='MAP')\n",
    "print('Transition matrix shape:', P.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction output transform\n",
    "\n",
    "Apply the transition models to generate distributions over future states. These distributions need to be sent back to the state space, because we need to plug them into a regressor trained in the state space later. There are several concievable ways to go from a distribution over states to an element of the state space, and this cell provides an interface for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document these!\n",
    "def predict(list_of_seqs, P, N_steps, num_unique_states):\n",
    "    in_flat = np.concatenate([item[:-N_steps] for item in list_of_seqs])\n",
    "    one_hot_prediction_input = one_hot_encode(in_flat, num_states = num_unique_states)\n",
    "    pred = np.power(P, N_steps)\n",
    "    # calculate a distribution over future states\n",
    "    return pred @ one_hot_prediction_input\n",
    "\n",
    "def list_to_prediction_targets(list_of_seqs, N_steps, labels, state_set):\n",
    "    targets = np.concatenate([item[N_steps:] for item in list_of_seqs])\n",
    "    return lookup_states(targets, labels, state_set)\n",
    "\n",
    "def prediction_output_transform(pred_out, labels, state_set, mode):\n",
    "    if mode == 'activity_dist':\n",
    "        return state_dist_to_activity_dist(pred_out, labels, state_set)\n",
    "    elif mode == 'argmax':\n",
    "        return state_dist_to_most_likely_state(pred_out, labels, state_set)\n",
    "    elif mode == 'nearest_neighbor':\n",
    "        distribution = state_dist_to_activity_dist(pred_out, labels, state_set)\n",
    "        return distribution >= 0.5\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown prediction output transform!\")\n",
    "        \n",
    "def bit_flips(prediction_dist, target):\n",
    "    dist_rounded = prediction_dist >= 0.5\n",
    "    loss = dist_rounded.astype(int) == target.astype(int)\n",
    "    return 1 - loss.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction loss over the data for 1 time step(s): mean: 0.4523963185924837 std: 0.09233427479952037\n",
      "Prediction bit flips over the data for 1 time step(s): mean: 0.21349206349206348 std: 0.07196635546289737\n"
     ]
    }
   ],
   "source": [
    "N_steps = 1\n",
    "estimate = predict(valid_set_prediction, P, N_steps, num_unique_states)\n",
    "# convert to sets of individual distributions over activity components\n",
    "prediction = prediction_output_transform(estimate, dataset_df['out_labels'].values, states, 'activity_dist')\n",
    "# simple targets - just time-shifted the input by N_steps\n",
    "pred_targets = list_to_prediction_targets(valid_set_prediction, N_steps, dataset_df['out_labels'].values, states)\n",
    "# calculate loss\n",
    "loss = BCE(prediction, pred_targets) #percentage bitflips as alternatives\n",
    "loss_bit = bit_flips(prediction, pred_targets) #percentage bitflips as alternatives\n",
    "# print reduced loss\n",
    "print('Prediction loss over the data for', N_steps, 'time step(s): mean:', loss.mean(), 'std:', loss.std())\n",
    "print('Prediction bit flips over the data for', N_steps, 'time step(s): mean:', loss_bit.mean(), 'std:', loss_bit.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the target space\n",
    "\n",
    "Sebastian already offered some advice here, like taking the square root of the values to allow for a better line fit through them. This cell provides an interface for such techniques. Note that these should always be invertible, because we need to convert the regressor output back to the original target space. This should be implemented in the 'Backward' direction case.\n",
    "\n",
    "This part is a little hacky, and might need some changes to be able to elegantly account for using two regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_space_transform(targets, mode='Id', direction='Forward'):\n",
    "    if mode == 'Id':\n",
    "        if direction == 'Forward':\n",
    "            return targets\n",
    "        elif direction == 'Backward':\n",
    "            return targets\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unknown direction!\")\n",
    "    elif mode == 'Sqrt':\n",
    "        if direction == 'Forward':\n",
    "            return np.sqrt(np.abs(targets))\n",
    "        elif direction == 'Backward':\n",
    "            return -np.power(targets, 2)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Unknown direction!\")   \n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown target space transform!\")\n",
    "        \n",
    "targets_transformed = target_space_transform(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get training, validation and test sets for the regression component\n",
    "\n",
    "Do this for negative and positive targets separately!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression component train/valid/test here!\n",
      "Number of sequences in training set: 2200\n",
      "Number of sequences in validation set: 245\n"
     ]
    }
   ],
   "source": [
    "print('Regression component train/valid/test here!')\n",
    "ind_set_regressor = np.arange(targets_transformed.shape[0])\n",
    "ind_set_regressor = np.random.permutation(ind_set_regressor).astype(int)\n",
    "\n",
    "split = 0.9\n",
    "ind_set_regressor_train = ind_set_regressor[:int(split*len(ind_set_regressor))]\n",
    "ind_set_regressor_valid = ind_set_regressor[int(split*len(ind_set_regressor)):]\n",
    "\n",
    "print('Number of sequences in training set:', len(ind_set_regressor_train))\n",
    "print('Number of sequences in validation set:', len(ind_set_regressor_valid))\n",
    "\n",
    "train_states = states[ind_set_regressor_train]\n",
    "train_targets = targets_transformed[ind_set_regressor_train]\n",
    "\n",
    "valid_states = states[ind_set_regressor_valid]\n",
    "valid_targets = targets_transformed[ind_set_regressor_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe check what is X, and what is X.T here...\n",
    "def build_state_mat(states):\n",
    "    return np.concatenate([np.ones((states.shape[0],1)), states], axis=-1).T\n",
    "\n",
    "def fit_regressor(states, targets, mode='MLE', eps=1e-25):\n",
    "    X = build_state_mat(states)\n",
    "    if mode == 'MLE':\n",
    "        return np.linalg.inv(X @ X.T + eps*np.eye(X.shape[0])) @ X @ targets\n",
    "    elif mode == 'MAP':\n",
    "        var = targets.var()\n",
    "        return np.linalg.inv(X @ X.T + var*np.eye(X.shape[0])) @ X @ targets\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown regressor mode!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the charging training set: 88\n",
      "Number of samples in the discharging training set: 2112\n",
      "Number of samples in the charging valid set: 14\n",
      "Number of samples in the discharging valid set: 231\n",
      "Regressor L1 over the charging data: mean: 6.824713463756572 std: 4.93255997852312\n",
      "Regressor L1 over the discharging data: mean: 1.126126339002913 std: 3.267995721260056\n",
      "Regressor L1 over the data: mean: 1.4517598889888363 std: 3.6344779665913904\n"
     ]
    }
   ],
   "source": [
    "split_regressor = True\n",
    "regressor_mode = 'MAP'\n",
    "if split_regressor:\n",
    "    charging_transform_mode = 'Id'\n",
    "    discharging_transform_mode = 'Sqrt'\n",
    "    train_charging_mask = train_states[:,-1] > 0.5\n",
    "    train_discharging_mask = np.invert(train_charging_mask)\n",
    "    train_states_charging = train_states[train_charging_mask][:,:-1]\n",
    "    train_targets_charging = train_targets[train_charging_mask]\n",
    "    train_states_discharging = train_states[train_discharging_mask][:,:-1]\n",
    "    train_targets_discharging = train_targets[train_discharging_mask]\n",
    "    train_targets_charging_transformed = target_space_transform(train_targets_charging, mode=charging_transform_mode)\n",
    "    train_targets_discharging_transformed = target_space_transform(train_targets_discharging, mode=discharging_transform_mode)\n",
    "    \n",
    "    print('Number of samples in the charging training set:', train_targets_charging.shape[0])\n",
    "    print('Number of samples in the discharging training set:', train_targets_discharging.shape[0])\n",
    "    \n",
    "    w_charging = fit_regressor(train_states_charging, train_targets_charging_transformed, mode=regressor_mode)\n",
    "    w_discharging = fit_regressor(train_states_discharging, train_targets_discharging_transformed, mode=regressor_mode)\n",
    "    \n",
    "    valid_charging_mask = valid_states[:,-1] > 0.5\n",
    "    valid_discharging_mask = np.invert(valid_charging_mask)\n",
    "    valid_states_charging = valid_states[valid_charging_mask][:,:-1]\n",
    "    valid_states_discharging = valid_states[valid_discharging_mask][:,:-1]\n",
    "    valid_targets_charging = valid_targets[valid_charging_mask]\n",
    "    valid_targets_discharging = valid_targets[valid_discharging_mask]\n",
    "    valid_state_mat_charging = build_state_mat(valid_states_charging)\n",
    "    valid_state_mat_discharging = build_state_mat(valid_states_discharging)\n",
    "    valid_charging_out_transformed = valid_state_mat_charging.T @ w_charging\n",
    "    valid_discharging_out_transformed = valid_state_mat_discharging.T @ w_discharging\n",
    "    valid_charging_out = target_space_transform(valid_charging_out_transformed, mode=charging_transform_mode, direction='Backward')\n",
    "    valid_discharging_out = target_space_transform(valid_discharging_out_transformed, mode=discharging_transform_mode, direction='Backward')\n",
    "    loss_regressor_charging = np.abs(valid_charging_out - valid_targets_charging)\n",
    "    loss_regressor_discharging = np.abs(valid_discharging_out - valid_targets_discharging)\n",
    "    \n",
    "    print('Number of samples in the charging valid set:', valid_targets_charging.shape[0])\n",
    "    print('Number of samples in the discharging valid set:', valid_targets_discharging.shape[0])\n",
    "    \n",
    "    print('Regressor L1 over the charging data: mean:', loss_regressor_charging.mean(), 'std:', loss_regressor_charging.std())\n",
    "    print('Regressor L1 over the discharging data: mean:', loss_regressor_discharging.mean(), 'std:', loss_regressor_discharging.std())\n",
    "    \n",
    "    loss_regressor = np.concatenate([loss_regressor_charging, loss_regressor_discharging])\n",
    "    \n",
    "else:\n",
    "    transform_mode = 'Id'\n",
    "    train_targets_transformed = target_space_transform(train_targets, mode=transform_mode)\n",
    "    w = fit_regressor(train_states, train_targets_transformed, mode=regressor_mode)\n",
    "    \n",
    "    valid_state_mat = build_state_mat(valid_states)\n",
    "    valid_out_transformed = valid_state_mat.T @ w\n",
    "    valid_out = target_space_transform(valid_out_transformed, mode=transform_mode, direction='Backward')\n",
    "    loss_regressor = np.abs(valid_out - valid_targets)\n",
    "    \n",
    "print('Regressor L1 over the data: mean:', loss_regressor.mean(), 'std:', loss_regressor.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: MAP regression mode\n",
    "\n",
    "Need to implement this.\n",
    "\n",
    "### Combine Prediction and Regression\n",
    "\n",
    "Core idea: Pick one specific predictor, then do the regression on the same training set. Hopefully the validation scheme for the regressor will provide some justification for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
